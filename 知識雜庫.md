# 知識雜庫
# 目錄
[TOC]

# 相機模組
* 3A定義
    1. AF(Auto Focus) 自動對焦
    2. AE(Automatic Exposure) 自動曝光
    3. AWB(Automatic White Balance) 自動白平衡

# `.dll` & `.so`檔案
- `.dll`(Dynamic Link Library)動態連結庫，將程式封裝成一個庫，當你想使用他時就可以引用他，就像在exe檔案中引用函數一樣
    - 為甚麼是動態連結呢? 原因是只有程式碼在執行時才會進行載到記憶體空間，節省記憶體空間。
- `.so`(Shared object libraries)，Linux中的.so文件類似於Windows中的DLL，是動態鏈接庫，也有人譯作共享庫（因so的全稱為Shared Object）。當多個程序使用同一個動態鏈接庫時，既能節約可執行文件的大小，也能減少運行時的內存佔用

# V2L4
V2L4一個視訊與輸出裝置API與Linux的驅動程式框架
[Video4Linux](https://zh.wikipedia.org/zh-tw/Video4Linux)
能夠從裝置直接撈影像的資料出來，
韌體工程師正在處理這個並想辦法與軟體工程師串接。

# Image Stitching via Convolutional Neural Network
* 特徵提取網路以VGG16(分類網路)為主
* FMM以矩陣乘法達成計算特徵相似性
* IRM以3層卷積層與全連接層組成輸出16維的向量包含4個寬高與12個轉換矩陣(兩個6x6轉換矩陣)這部分可以用**RANSAC**去算
* 不是Open Source

# Raspberry Picamera2 
- 樹梅派上的Python library
- 能夠透過Config 調整從相機讀取的影響
## Configurations in more detai
![image](https://hackmd.io/_uploads/HJ2QQwnXR.png)
1. Camera Module 透過排線傳輸出未處理的影像至CSI-2 Receiver
2. CSI-2 Receiver負責傳輸影像到Memory
    * 數據傳輸
    * 偵數同步
    * 數據解碼
    * 檢測錯誤與校正
3. ISP讀取從Memeory中的影像，進行清理與前處理，在這裡可以輸出兩種影像
    * Main (RGB or YUV)
    * Low resolution -> "lores" image(RGB or YUV)

## Raw Data and the Sensor Configuration
* **bit_depth:** 每一個pixel用了多少bit
* **crop_limits:** 從一張全景圖像上能夠確實地擷取下來的大小
* **exposure_limits**: 曝光時間的最大小值 micro_second
* **fps:** mode不同支持不同最大的FPS
* **size:** sensor可以輸出的最大解析度


# 相機參數
相機參數分為包括 內部參數(Intrinsic Parameters)、外部參數(Extrinsic Parameters)以及失真系數(Distortion Coefficients)，
![image](https://hackmd.io/_uploads/ryfayWj7A.png =75%x)
Pinhole camera model

![image](https://hackmd.io/_uploads/S1EbcKtXA.png =75%x)
1. 坐標系 $(X_w, Y_w, Z_w)$ 為世界坐標系；
2. 坐標系 $(X_c, Y_c, Z_c)$ 為相機坐標系；
相機坐標系，以光心為原點，z軸為相機光軸，xy軸與圖像坐標系的xy軸平行。
3. 坐標系 $(x, y)$ 為圖像坐標系；
4. 坐標系 $(u, v)$ 為像素坐標系；

## 世界坐標系$(X_w, Y_w, Z_w)$轉換成相機坐標系$(X_c, Y_c, Z_c)$

從世界坐標系 $(X_w, Y_w, Z_w)$ 轉換到相機坐標系 $(X_c, Y_c, Z_c)$ 的公式如下：
\begin{align}
\begin{bmatrix}
X_c \\ Y_c \\ Z_c \\ 1
\end{bmatrix} =
\begin{bmatrix}
R & T \\
0 & 1
\end{bmatrix}
\begin{bmatrix}
X_w \\
Y_w \\
Z_w \\
1
\end{bmatrix}
\end{align}
其中，$R$ 是 $3 \times 3$ 的旋轉矩陣，$T$ 是 $3 \times 1$ 的平移向量。
### 說明
這邊就是相機外部參數了，其實相機對於世界坐標系原點，我們都可以透過一個平移向量移到對應的位置，並根據鏡頭方向會有一個旋轉的角度，所以其實相機座標可以透過$R,T$來轉換至世界座標反之亦然
- **旋轉矩陣 $R$**：用於描述相機坐標系相對於世界坐標系的旋轉。
    - 沿z軸方向的旋轉
    \begin{align}
    R_z(\alpha)=
    \begin{bmatrix} 
    \cos\alpha & \sin\alpha & 0 \\ 
    -\sin\alpha & \cos\alpha & 0 \\
    0 & 0 & 1
    \end{bmatrix}
    \end{align}
    - 沿x軸方向的旋轉
    \begin{align}
    R_x(\beta)=
    \begin{bmatrix} 
    1 & 0 & 0 \\ 
    0 & \cos\beta & \sin\beta \\
    0 & -sin\beta & \cos\beta 
    \end{bmatrix}
    \end{align}
    - 沿y軸方向的旋轉
    \begin{align}
    R_y(\gamma)=
    \begin{bmatrix} 
    0 & cos\gamma & -\sin\gamma \\ 
    0 & 1 & 0 \\
    0 & sin\gamma & \cos\gamma 
    \end{bmatrix}
    \end{align}
    得到最後將其結合起來變成 $R = R_z(\alpha)R_x(\beta)R_y(\gamma)$
- **平移向量 $T$**：用於描述相機坐標系相對於世界坐標系的平移
    \begin{align}
    T = \begin{bmatrix} T_x \\ T_y \\ T_z \end{bmatrix}  
    \end{align}
- **齊次坐標**：使用齊次坐標表示可以方便地將旋轉和平移合併到同一個矩陣中進行計算，就是多一個維度啦。

## 相機坐標系$(X_c, Y_c, Z_c)$轉換成圖像坐標系$(x, y)$
![image](https://hackmd.io/_uploads/Sylzed3m0.png =70%x)
相機坐標系的原點$O_c$到圖像坐標系的原點$O$的距離稱為焦距$f$，接著透過相似三角形的概念，三角形$\Delta O_{c}BA$與$O_{c}Co$相似，與$\Delta O_{c}pC$ 與$\Delta O_{c}PB$可以推得
\begin{align}
\frac{f}{Z_c} = \frac{x} {X_c} = \frac{y}{Y_c}
\end{align}
便可以得到
\begin{align}
x = \frac{f}{Z_c}X_c \\ 
y = \frac{f}{Z_c}Y_c 
\end{align}

從相機坐標系 $(X_c, Y_c, Z_c)$ 轉換到圖像坐標系 $(x, y)$ 的公式如下：
\begin{align}
Z_c
\begin{bmatrix}
x \\ y \\ 1 
\end{bmatrix}=
\begin{bmatrix}
f_x & 0 & 0 \\
0 & f_y & 0 \\
0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
X_c \\ Y_c \\ 1
\end{bmatrix}
\end{align}
### 說明
- **內參矩陣**：$K = \begin{bmatrix} f_x & 0 & 0 \\ 0 & f_y & 0 \\ 0 & 0 & 1 \end{bmatrix}$ 這個還不是內參矩陣喔
- $f :$ 是焦距
- $s :$ Skew coefficient, which is non-zero if the image axes are not perpendicular.


## 圖像坐標系$(x, y)$轉換成像素坐標系$(u, v)$
![image](https://hackmd.io/_uploads/Bk-MquhmR.png)
圖像坐標系與像素座標系都在同一個平面上，只是各自原點與度量單位不太一樣，圖像座標系的原點是光軸與其平面的交點，這個我們通常稱為principal point，圖像坐標系的單位式mm而像素坐標系的單位是pixel，也就是我們需要一個轉換方式，$dx, dy$就是表示每一行每一列有多少的mm即1(pixel) = dx(mm)

### 說明
\begin{align}
\begin{bmatrix} u \\ v \\ 1\end{bmatrix}=
\begin{bmatrix} 
\frac{1}{dx} & 0 & u_0 \\ 
0 & \frac{1}{dy}  & v_0 \\
0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
x \\ y \\ 1 
\end{bmatrix}
\end{align}

- $dx, dy :$ 代表一個pixel是多少mm
- $u_0, v_0 :$ 代表偏移量(這邊還不能確定是不是principal point

# Camera Calibration and 3D Reconstruction 
## Distortion 畸變
$\because$ 光進入相機時，透鏡邊緣會造成光偏移
$\therefore$ 成像時會有畸變發生
![image](https://hackmd.io/_uploads/ryREyCamC.png)
由於光在經過透鏡邊緣時，其彎曲的程度會比在透鏡中心點大，透鏡越小的時候，其distortion越大，下面的圖片說明在輻射畸變下的兩種不同畸變
1. Barrel 桶狀畸變
2. Pincushion 枕狀畸變
![image](https://hackmd.io/_uploads/Hk7-UhfV0.png)

- Radial distortion 輻射畸變
  $x_{dis} = x(1+k_1 r^2+k_2 r^4+k_3 r^6)$
  $y_{dis} = y(1+k_1 r^2+k_2 r^4+k_3 r^6)$
- Tangential  distortion 切向取變
  $x_{dis} = x + \big(2p_{1}xy + p_{2}(r^2+2x^2) \big)$ 
  $y_{dis} = y + \big( p_{1}(r^2+ 2y^2)+ 2p_{2}xy)$
 
## 畸變相機模型 Camera Model with Distortion
將上面兩個式子結合起來，因為一個是乘法一個是加法，彼此不互相干擾
1. \\( x'' \\) 和 \\( y'' \\) 的原方程式：
\begin{align} 
x'' &= x'(k_1 r^2 + k_2 r^4 + k_3 r^6 + \cdots ) + p_1 (2x'^2 + r^2) + 2p_2 x' y' \\
y'' &= y' (k_1 r^2 + k_2 r^4 + k_3 r^6 + \cdots) + 2p_1 x' y' + p_2 (2y'^2 + r^2)
\end{align}
- $r^2 = x'^2 + y'^2 :$ 光學中心到點$(x',y')$的距離
- $k_1, k_2, k_3 :$ 是徑向畸變係數
- $p_1, p_2 :$ 是切向畸變係數。

\begin{align}
\begin{bmatrix}
u \\ v
\end{bmatrix} = \begin{bmatrix}
f_x x'' + c_x \\
f_y y'' + c_y
\end{bmatrix}
\end{align}

\begin{align}
\begin{bmatrix}
x'' \\
y''
\end{bmatrix} = 
\begin{bmatrix}
x' \frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6} + 2 p_1 x' y' + p_2(r^2 + 2 x'^2) + s_1 r^2 + s_2 r^4 \\
y' \frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6} + p_1 (r^2 + 2 y'^2) + 2 p_2 x' y' + s_3 r^2 + s_4 r^4 \\
\end{bmatrix}
\end{align}

## 相機校正 Camera Calibration
1. **Capture Calibration Images:**
   * **What :** 錄製有特定Pattern的影像，通常是棋盤格。
   * **Why :** 棋盤格提供了明確的角點資訊，這些角點可以用於計算相機的內參數和畸變係數。
   * **How :** 拍攝多張包含棋盤格的影像，每張影像需從不同的角度和位置拍攝，以確保覆蓋了整個相機的視野
   ![image](https://hackmd.io/_uploads/SyBlcb7N0.png =50%x)
    $\because$ 棋盤格提供角點資訊
    $\because$ 棋盤格在影像中更抗噪
    $\because$ 棋盤格容易取得
2. **Detect Corners:**
* **What :** 偵測影像中棋盤格的角點位置。 
* **Why :** 角點是校正過程中的關鍵特徵點，用於計算相機參數。 
* **How :** 使用OpenCV中的`cv2.findChessboardCorners`函數來偵測影像中的角點，並將其儲存在`imgpoints`列表中。 
```python 
ret, corners = cv2.findChessboardCorners(gray, (9, 6), None) if ret: imgpoints.append(corners) objpoints.append(objp)
```
3. **Calibrate Camera:**
   * 張氏標記法
```python
ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(
  objpoints, imgpoints, gray.shape[::-1]
)
```
- `ret` 表示標定成功與否
- `mtx` 內參矩陣
\begin{align}
\begin{bmatrix} 
f_x & 0 & c_x \\ 
0 & f_y & c_y \\ 
0 & 0 & 1
\end{bmatrix}
\end{align}
- `dist` 畸變參數
\begin{align} 
x'' &= x'(k_1 r^2 + k_2 r^4 + k_3 r^6) + p_1 (2x'^2 + r^2) + 2p_2 x'y' \\
y'' &= y' (k_1 r^2 + k_2 r^4 + k_3 r^6) + 2p_1 x' y' + p_2 (2y'^2 + r^2)
\end{align}
\begin{align}
Distortion \ coefficients=(k_1, k_2, k_3, p_1, p_2)
\end{align}
- `rvecs` 棋盤格圖像對應到的旋轉向量 世界 $\rightarrow$ 相機
- `dist` 棋盤格圖像對應到的平移向量 世界 $\rightarrow$ 相機
4. **Un-distort Images:**
* Project point
5. **Evaluate Calibration:**

* Compute Error
將理想投影點進行轉換至實際影像並與實際觀察到的影像中的點之間的差異。
\begin{align}
\text{Mean Error} = \frac{1}{N} \sum_{i=1}^{N} \frac{\| \text{Projected Image Points}_i - \text{Actual Image Points}_i \|_2}{\text{Number of Image Points}_i}
\end{align}
6. **Save Parameters:**
# Jump!
[工作儀表板](/Hyt7uv0rRNCTEcpVLxjxuw)